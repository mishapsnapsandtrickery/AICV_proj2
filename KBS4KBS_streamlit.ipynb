{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6eKqsORvpr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e67446c4-de59-4a05-a9eb-eb4d9a160bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.223-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.223-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.223 ultralytics-thop-2.0.18\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118 -q || true\n",
        "!pip install streamlit pyngrok pillow opencv-python-headless matplotlib -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUC5vBqwxHd4",
        "outputId": "0fb9e1ab-18b5-416a-e8ef-f6c49472e628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/11n_150e_best.pt\"\n",
        "print(\"모델 경로:\", model_path)"
      ],
      "metadata": {
        "id": "U8IniOyAvuQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcbb3a0d-c47c-4f97-85dd-6e602a42b345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델 경로: /content/11n_150e_best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## best.pt 파일의 경로를 설정해주세요."
      ],
      "metadata": {
        "id": "pOzbD3ZALDuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"git+https://github.com/facebookresearch/segment-anything-2.git\" tqdm\n",
        "from sam2.sam2_image_predictor import SAM2ImagePredictor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBhmUv8hODxS",
        "outputId": "86d5825c-6004-472e-a465-1914d4ad3ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/segment-anything-2.git\n",
            "  Cloning https://github.com/facebookresearch/segment-anything-2.git to /tmp/pip-req-build-6gr0qjtv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything-2.git /tmp/pip-req-build-6gr0qjtv\n",
            "  Resolved https://github.com/facebookresearch/segment-anything-2.git to commit 2b90b9f5ceec907a1c18123530e92e794ad901a4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > app.py <<'PY'\n",
        "# app.py — YOLOv11n-seg + 클래스별 마스크 멀티체크 + Gemini 2.5 Flash-Lite VLM\n",
        "import os, io, json, math\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# pip install google-genai\n",
        "# pip install python-dotenv\n",
        "\n",
        "# ===================== YOLO 부분 =====================\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    from ultralytics import YOLO\n",
        "    model_path = \"/content/11n_150e_best.pt\"  # YOLOv11n-seg 가중치\n",
        "    model = YOLO(model_path)\n",
        "    return model\n",
        "\n",
        "def resize_for_model(img, short_side=640):\n",
        "    w, h = img.size\n",
        "    if min(w, h) == short_side:\n",
        "        return img\n",
        "    if w < h:\n",
        "        new_w = short_side\n",
        "        new_h = int(h * (short_side / w))\n",
        "    else:\n",
        "        new_h = short_side\n",
        "        new_w = int(w * (short_side / h))\n",
        "    return img.resize((new_w, new_h), Image.BILINEAR)\n",
        "\n",
        "def mask_to_rgba(mask_arr, color=(255, 0, 0), alpha=128):\n",
        "    h, w = mask_arr.shape\n",
        "    rgba = np.zeros((h, w, 4), dtype=np.uint8)\n",
        "    rgba[..., 0:3] = color\n",
        "    rgba[..., 3] = (mask_arr * alpha).astype(np.uint8)\n",
        "    return Image.fromarray(rgba, \"RGBA\")\n",
        "\n",
        "def compute_geometry(mask, gsd):\n",
        "    \"\"\"mask: 0/1, gsd[m/pixel] -> 면적/길이/너비/페렛지수[m]\"\"\"\n",
        "    res = {}\n",
        "    pixel_count = np.sum(mask)\n",
        "    res[\"area_m2\"] = float(pixel_count * (gsd ** 2))\n",
        "    mask_u8 = (mask * 255).astype(np.uint8)\n",
        "    contours, _ = cv2.findContours(mask_u8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if len(contours) == 0:\n",
        "        res.update({\"length_m\": 0.0, \"width_m\": 0.0, \"feret_m\": 0.0})\n",
        "        return res\n",
        "    cnt = max(contours, key=cv2.contourArea)\n",
        "    ((cx, cy), (w, h), _) = cv2.minAreaRect(cnt)\n",
        "    res[\"length_m\"] = float(max(w, h) * gsd)\n",
        "    res[\"width_m\"]  = float(min(w, h) * gsd)\n",
        "    # 페렛 지수(최대 거리)\n",
        "    pts = cnt.reshape(-1, 2)\n",
        "    max_d2 = 0.0\n",
        "    # 간단 다운샘플링\n",
        "    step = max(1, len(pts)//2000)\n",
        "    P = pts[::step]\n",
        "    for i in range(0, len(P), 256):\n",
        "        block = P[i:i+256]\n",
        "        d2 = np.sum((block[:, None, :] - P[None, :, :]) ** 2, axis=2)\n",
        "        max_d2 = max(max_d2, float(d2.max()))\n",
        "    res[\"feret_m\"] = float(math.sqrt(max_d2) * gsd)\n",
        "    return res\n",
        "\n",
        "def overlay_masks_on_image(pil_img, masks_list, colors=None):\n",
        "    base = pil_img.convert(\"RGBA\")\n",
        "    out = Image.new(\"RGBA\", base.size)\n",
        "    if colors is None:\n",
        "        colors = [\n",
        "            (255, 0, 0), (0, 255, 0), (0, 0, 255),\n",
        "            (255, 255, 0), (255, 0, 255), (0, 255, 255),\n",
        "            (255, 128, 0), (128, 0, 255)\n",
        "        ]\n",
        "    for i, m in enumerate(masks_list):\n",
        "        c = colors[i % len(colors)]\n",
        "        mask_rgba = mask_to_rgba(m.astype(np.uint8), color=c, alpha=120)\n",
        "        out = Image.alpha_composite(out, mask_rgba)\n",
        "    combined = Image.alpha_composite(base, out)\n",
        "    return combined.convert(\"RGB\")\n",
        "\n",
        "# ===================== YOLO + SAM2 추론 =====================\n",
        "from sam2 import SAM2ImagePredictor  # SAM2 라이브러리 임포트 필요\n",
        "\n",
        "@st.cache_resource\n",
        "def load_sam2_predictor(model_name=\"facebook/sam2-hiera-tiny\", device=\"cuda\"):\n",
        "    predictor = SAM2ImagePredictor.from_pretrained(model_name)\n",
        "    predictor.model.to(device)\n",
        "    predictor.model.eval()\n",
        "    return predictor\n",
        "\n",
        "def run_inference(model, pil_img, conf=0.25, imgsz=640, sam2_model_name=\"facebook/sam2-hiera-tiny\"):\n",
        "    \"\"\"\n",
        "    YOLOv11n-seg + SAM2 기반 마스크 생성\n",
        "    - pil_img: 업로드된 원본 이미지 (PIL)\n",
        "    - conf: confidence threshold\n",
        "    - imgsz: 입력 이미지 크기\n",
        "    - sam2_model_name: 사용할 SAM2 모델명\n",
        "    \"\"\"\n",
        "    import torch\n",
        "    import numpy as np\n",
        "    import cv2\n",
        "\n",
        "    # 디바이스 설정\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # 1️⃣ 이미지 변환\n",
        "    np_img = np.array(pil_img)\n",
        "    h, w = np_img.shape[:2]\n",
        "\n",
        "    # 2️⃣ YOLO 추론\n",
        "    results = model.predict(source=np_img, conf=conf, imgsz=imgsz, device=device, verbose=False)\n",
        "    r = results[0]\n",
        "\n",
        "    boxes = r.boxes.xyxy.cpu().numpy() if hasattr(r, \"boxes\") and r.boxes is not None else []\n",
        "    labels = r.boxes.cls.cpu().numpy().astype(int).tolist() if hasattr(r, \"boxes\") and r.boxes is not None else []\n",
        "    scores = r.boxes.conf.cpu().numpy().tolist() if hasattr(r, \"boxes\") and r.boxes is not None else []\n",
        "\n",
        "    if len(boxes) == 0:\n",
        "        return [], [], [], {}\n",
        "\n",
        "    # 3️⃣ SAM2 Predictor 로드 (캐시 활용)\n",
        "    predictor = load_sam2_predictor(model_name=sam2_model_name, device=device)\n",
        "\n",
        "    # 4️⃣ 이미지 세팅 및 마스크 생성\n",
        "    predictor.set_image(np_img)\n",
        "    masks = []\n",
        "    for box in boxes:\n",
        "        masks_pred, _, _ = predictor.predict(box=box, multimask_output=False)\n",
        "        mask_bin = masks_pred[0].astype(np.uint8)\n",
        "        if mask_bin.shape != (h, w):\n",
        "            mask_bin = cv2.resize(mask_bin, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "        masks.append(mask_bin)\n",
        "\n",
        "    # YOLO 클래스 이름 매핑\n",
        "    names = r.names if hasattr(r, \"names\") else {i: f\"class_{i}\" for i in range(len(masks))}\n",
        "\n",
        "    return masks, labels, scores, names\n",
        "\n",
        "# ===================== Gemini VLM 부분 =====================\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import streamlit as st\n",
        "\n",
        "\n",
        "def get_api_key():\n",
        "    # .env 파일 로드 (파일명은 실제 파일 이름으로 변경)\n",
        "    load_dotenv(\"/content/googleapi_KE.env\")\n",
        "\n",
        "    # 환경변수에서 API 키 가져오기\n",
        "    api_key = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
        "\n",
        "    if not api_key:\n",
        "        st.warning(\"API 키를 찾을 수 없습니다. googleapi_KE.env 파일을 확인하세요.\")\n",
        "    return api_key\n",
        "\n",
        "\n",
        "def ndarray_to_jpeg_bytes(pil_img: Image.Image) -> bytes:\n",
        "    buf = io.BytesIO()\n",
        "    pil_img.save(buf, format=\"JPEG\", quality=90)\n",
        "    return buf.getvalue()\n",
        "\n",
        "EXPERT_PROMPT_TMPL = \"\"\"[역할]\n",
        "당신은 토목구조(교량) 외관 손상평가 전문가이자 품질보증 엔지니어입니다.\n",
        "불확실한 정보는 추정하지 말고 \"정보 부족\"으로 표기합니다.\n",
        "\n",
        "[목표]\n",
        "입력된 (1) 세그멘테이션 수치 JSON, (2) 원본 이미지, (3) 마스크 오버레이,\n",
        "(4) 사용자 입력 교량 정보(종류/등급)를 바탕으로\n",
        "간결하고 근거 중심의 전문가 보고 요약을 작성합니다.\n",
        "\n",
        "[데이터 해석 규칙]\n",
        "- 수치(JSON) 우선 신뢰. 이미지와 모순 시 모순 사실을 [모순] 태그로 명시.\n",
        "- 위험도 평가 시 기준(예: 손상 길이/면적 상대적 크기, 노출 위험, 누수·부식 동반 여부)을 근거로 제시.\n",
        "- 단정 금지: 불확실/추정은 [불확실]로 표기.\n",
        "- 허위 지식 금지: 출처 없는 규정·코드 인용 금지.\n",
        "\n",
        "[출력 스타일]\n",
        "- 한국어, 전문가 톤, 불필요한 수식어 금지.\n",
        "- 섹션: ①요약(3~5문장) ②세부분석 ③권고사항\n",
        "- ③권고사항은 세부분석 내용을 기반으로 작성. 구체적 행동지침(예: 추가조사, 보수방법) 포함.\n",
        "- 수치는 가능한 한 입력값을 재사용(단위 표기 일관성).\n",
        "- 문장/목록 혼용 허용. 과장 표현 금지.\n",
        "\n",
        "[입력]\n",
        "- 세그 JSON: {seg_json}\n",
        "- 메타(사용자 입력): 교량종류={bridge_type}, 등급={bridge_grade}\n",
        "- 원본 이미지 및 오버레이 이미지는 첨부됨.\n",
        "\n",
        "[출력 예시 1  균열 및 백태 동반 사례]\n",
        "① 요약\n",
        "PSC Beam교(B등급) 복부 하단부에서 종방향 균열(길이 0.13 m, 폭 2 mm) 및 백태가 동반된 손상이 검출됨.\n",
        "균열은 긴장력 손실 또는 피복층 건조수축의 영향으로 추정되며, 구조적 영향은 경미하나 수분 침투 위험이 존재함.\n",
        "백태는 균열부로 유입된 수분의 염분 결정화 현상으로 판단됨.\n",
        "철근 노출은 확인되지 않았으며, 장기적으로 피복층 열화 확산 가능성 있음.\n",
        "\n",
        "② 세부분석\n",
        "- **균열(Crack)**: 길이 0.13 m, 폭 0.002 m, 면적 0.00042 m². 종방향으로 뚜렷하게 발달하였으며 긴장력 전달 구간의 인장응력 집중이 원인으로 추정됨. 백태가 균열선을 따라 형성되어 있어, 균열 내부의 수분 이동이 지속되고 있음을 시사함.\n",
        "- **표면 변화(백태)**: 밝은 흰색 침전물이 균열부를 따라 분포, 이는 모세관 작용에 의한 내부 수분 증발 후 염 결정화로 판단됨.오버레이 상 일부 경계 불명확 구간은 [모순].\n",
        "- **구조적 영향**: 철근 근접 깊이는 정보 부족, 피복 손상은 초기 단계로 평가됨.\n",
        "\n",
        "③ 권고사항\n",
        "- 균열 폭 및 깊이 실측 후, 폭 0.3 mm 이상 시 폴리우레탄계 충전재 주입 실시.\n",
        "- 표면 백태 부위는 고압수 세척 후 실리콘계 방수제 도포.\n",
        "- 추적 관찰을 위해 6개월 주기 균열계측기 부착 권장.\n",
        "- 부식 징후 발생 시 피복 복원 전 방청도료 도포 절차 병행.\n",
        "\n",
        "---\n",
        "\n",
        "[출력 예시 2  박리 및 철근 부식 의심 사례]\n",
        "① 요약\n",
        "RC 슬래브교(C등급) 저면부에서 콘크리트 박리(면적 0.0045 m²)와 내부 철근 변색이 확인됨.\n",
        "박리는 피복층 박락으로 추정되며, 하부 누수 흔적이 함께 관찰되어 염화물 침투 가능성 있음.\n",
        "세그멘테이션 결과 면적은 국부적이지만, 철근 노출 여부는 [불확실].\n",
        "현재 상태는 국부 부식 개시 단계로 판단됨.\n",
        "\n",
        "② 세부분석\n",
        "- **박리(Spalling)**: 면적 0.0045 m², 폭 0.03 m, 신뢰도 0.83. 경계 불규칙하며 하중 재하 구간 인근에 위치.\n",
        "  균열이 박리부 주변에서 방사형으로 확산되어 있어, **동결융해 반복 또는 염화물 축적**이 주요 원인으로 판단됨.\n",
        "- **부식(Corrosion)**: 오버레이 이미지에서 녹색~적갈색 변색 영역이 확인되어, 철근 산화 생성물로 추정됨. 실제 피복 두께 및 철근 직경 정보 부족으로 정확한 진행 정도는 [불확실].\n",
        "- **환경조건**: 하부 배수 미비 및 장기 누수 흔적 관찰, 콘크리트 내 염분 농도 상승 가능성 있음.\n",
        "\n",
        "③ 권고사항\n",
        "- 박리부 콘크리트 제거 후, 노출 철근의 부식 정도 육안확인 및 방청도료 도포 실시.\n",
        "- 보수는 폴리머 시멘트 모르타르 충전 방식 적용, 최소 피복두께 25 mm 확보.\n",
        "- 누수 원인 구간 배수로 재정비 및 표면 방수층 보강 병행.\n",
        "- 장기적 내구성 확보를 위해 1년 내 정기점검 포함 정밀안전진단 병행 권장.\n",
        "\"\"\"\n",
        "\n",
        "def call_gemini_vlm(img_rgb: Image.Image,\n",
        "                    overlay_rgb: Image.Image,\n",
        "                    seg_summary: dict,\n",
        "                    bridge_type: str,\n",
        "                    bridge_grade: str,\n",
        "                    mode: str = \"expert\") -> str:\n",
        "    \"\"\"\n",
        "    mode: 'expert' -> 전문가 보고서 톤 / 'light' -> 짧은 요점만\n",
        "    \"\"\"\n",
        "    api_key = get_api_key()\n",
        "    if not api_key:\n",
        "        raise RuntimeError(\"GOOGLE_API_KEY 가 없습니다.\")\n",
        "\n",
        "    client = genai.Client(api_key=api_key)\n",
        "    MODEL = \"gemini-2.5-flash-lite\"\n",
        "\n",
        "    if mode == \"expert\":\n",
        "        prompt = EXPERT_PROMPT_TMPL.format(\n",
        "            seg_json=json.dumps(seg_summary, ensure_ascii=False),\n",
        "            bridge_type=bridge_type,\n",
        "            bridge_grade=bridge_grade\n",
        "        )\n",
        "    else:\n",
        "        prompt = (\n",
        "            \"아래 자료(세그 JSON + 원본 + 오버레이)를 바탕으로 핵심만 5줄 이내 bullet로 요약.\\n\"\n",
        "            f\"세그 JSON: {json.dumps(seg_summary, ensure_ascii=False)}\\n\"\n",
        "            f\"교량종류={bridge_type}, 등급={bridge_grade}\\n\"\n",
        "        )\n",
        "\n",
        "    img_bytes = ndarray_to_jpeg_bytes(img_rgb)\n",
        "    ovl_bytes = ndarray_to_jpeg_bytes(overlay_rgb)\n",
        "\n",
        "    contents = types.Content(\n",
        "        role=\"user\",\n",
        "        parts=[\n",
        "            types.Part(text=prompt),\n",
        "            types.Part(text=\"원본 이미지:\"),\n",
        "            types.Part(inline_data=types.Blob(mime_type=\"image/jpeg\", data=img_bytes)),\n",
        "            types.Part(text=\"마스크 오버레이 이미지:\"),\n",
        "            types.Part(inline_data=types.Blob(mime_type=\"image/jpeg\", data=ovl_bytes)),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    resp = client.models.generate_content(\n",
        "        model=MODEL,\n",
        "        contents=contents,\n",
        "        config=types.GenerateContentConfig(\n",
        "            thinking_config=types.ThinkingConfig(thinking_budget=-1),  # 동적 추론\n",
        "            max_output_tokens=5000 if mode==\"expert\" else 1500,\n",
        "            temperature=0.2\n",
        "        )\n",
        "    )\n",
        "    return resp.text\n",
        "\n",
        "# ===================== Streamlit UI =====================\n",
        "st.set_page_config(page_title=\"YOLOv11n-seg + Gemini VLM\", layout=\"wide\")\n",
        "st.title(\"YOLOv11n-seg → Metrics → Gemini 2.5 Flash-Lite\")\n",
        "\n",
        "st.info(\"모델 로드 중…\")\n",
        "model_obj = load_model()\n",
        "st.success(\"모델 로드 완료! (best.pt)\")\n",
        "\n",
        "# Sidebar: 추론 설정\n",
        "conf_th = st.sidebar.slider(\"Confidence threshold\", 0.0, 1.0, 0.25, 0.01)\n",
        "imgsz = st.sidebar.number_input(\"이미지 short side\", value=640, step=32)\n",
        "show_raw = st.sidebar.checkbox(\"원본 이미지 보기\", True)\n",
        "\n",
        "# Sidebar: 교량 정보\n",
        "st.sidebar.title(\"교량 정보 입력(테스트 환경)\")\n",
        "bridge_grade = st.sidebar.selectbox(\"교량 등급:\", [\"1등급\", \"2등급\", \"3등급\", \"미상\"])\n",
        "\n",
        "bridge_type_options = {\n",
        "    \"RG (RCT 거더교)\": \"RG\", \"BG (RC 박스 거더교)\": \"BG\", \"IG (PSCI I 거더교)\": \"IG\",\n",
        "    \"PG (PSC 박스거더교)\": \"PG\", \"SP (강플레이트 거더교)\": \"SP\", \"SB (강박스 거더교)\": \"SB\",\n",
        "    \"PF (프리플랙스교)\": \"PF\", \"RS (RC 슬래브교)\": \"RS\", \"PS (PC 슬래브교)\": \"PS\",\n",
        "    \"VS (PC 중공슬래브교)\": \"VS\", \"CR (콘크리트라멘교)\": \"CR\", \"SR (강라멘교)\": \"SR\",\n",
        "    \"CA (콘크리트아치교)\": \"CA\", \"SA (강아치교)\": \"SA\", \"TR (트러스교)\": \"TR\",\n",
        "    \"CS (사장교)\": \"CS\", \"UN (미상)\": \"UN\"\n",
        "}\n",
        "bridge_type_label = st.sidebar.selectbox(\"교량 종류:\", list(bridge_type_options.keys()))\n",
        "bridge_type = bridge_type_options[bridge_type_label]\n",
        "\n",
        "st.sidebar.markdown(\"---\")\n",
        "gsd = st.sidebar.number_input(\"GSD [m/pixel]\", min_value=0.0, value=0.005, step=0.001, format=\"%.6f\")\n",
        "st.sidebar.caption(\"예: 1 픽셀 = 0.5 cm → 0.005 m\")\n",
        "\n",
        "# 이미지 업로드\n",
        "uploaded = st.file_uploader(\"이미지 업로드\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "if uploaded is not None:\n",
        "    img = Image.open(uploaded).convert(\"RGB\")\n",
        "    if show_raw:\n",
        "        st.image(img, caption=\"원본 이미지\", use_container_width=True)\n",
        "\n",
        "    resized = resize_for_model(img, short_side=int(imgsz))\n",
        "    masks, labels, scores, names = run_inference(model_obj, resized, conf=conf_th, imgsz=int(imgsz))\n",
        "\n",
        "    if len(masks) == 0:\n",
        "        st.warning(\"감지된 마스크가 없습니다.\")\n",
        "        st.stop()\n",
        "\n",
        "    # 마스크들을 원본 크기로 되돌림\n",
        "    final_masks = []\n",
        "    for m in masks:\n",
        "        mask_img = Image.fromarray((m * 255).astype(np.uint8))\n",
        "        mask_orig = mask_img.resize(img.size, resample=Image.NEAREST)\n",
        "        final_masks.append(np.array(mask_orig) // 255)\n",
        "\n",
        "    # 클래스 이름 매핑\n",
        "    class_names = names if isinstance(names, dict) else {i: n for i, n in enumerate(names)}\n",
        "\n",
        "    # 사이드바: 표시할 클래스 선택\n",
        "    st.sidebar.markdown(\"### 표시할 결함 클래스 선택\")\n",
        "    # 가중치의 클래스 이름을 그대로 체크박스에 사용\n",
        "    unique_names = sorted(set(class_names.values()))\n",
        "    class_check = {cname: st.sidebar.checkbox(cname, value=True) for cname in unique_names}\n",
        "    selected_classes = [k for k, v in class_check.items() if v]\n",
        "\n",
        "    # 선택 클래스 필터링\n",
        "    filtered_masks, filtered_labels, filtered_scores = [], [], []\n",
        "    # 라벨/스코어 길이 체크\n",
        "    if len(labels) != len(final_masks):\n",
        "        # 박스가 없거나 길이 불일치 시 Unknown 처리\n",
        "        labels = [ -1 for _ in range(len(final_masks)) ]\n",
        "        filtered_labels_tmp = []\n",
        "\n",
        "    for m, l, s in zip(final_masks, labels, scores if len(scores)==len(final_masks) else [0.0]*len(final_masks)):\n",
        "        cname = class_names.get(l, \"Unknown\")\n",
        "        if cname in selected_classes:\n",
        "            filtered_masks.append(m)\n",
        "            filtered_labels.append(l)\n",
        "            filtered_scores.append(float(s))\n",
        "\n",
        "    # 오버레이 생성/표시\n",
        "    if len(filtered_masks) > 0:\n",
        "        overlay = overlay_masks_on_image(img, filtered_masks)\n",
        "        st.image(overlay, caption=f\"표시 중: {', '.join(selected_classes)}\", use_container_width=True)\n",
        "    else:\n",
        "        st.image(img, caption=\"선택된 클래스가 없습니다.\", use_container_width=True)\n",
        "\n",
        "    # 표 생성\n",
        "    data = []\n",
        "    for i, m in enumerate(filtered_masks):\n",
        "        geom = compute_geometry(m, gsd)\n",
        "        cname = class_names.get(filtered_labels[i], \"Unknown\")\n",
        "        row = {\n",
        "            \"index\": i,\n",
        "            \"class\": cname,\n",
        "            \"score\": filtered_scores[i] if i < len(filtered_scores) else 0.0,\n",
        "            \"area(m^2)\": geom[\"area_m2\"],\n",
        "            \"length(m)\": geom[\"length_m\"],\n",
        "            \"width(m)\": geom[\"width_m\"],\n",
        "            \"feret(m)\": geom[\"feret_m\"]\n",
        "        }\n",
        "        data.append(row)\n",
        "    df = pd.DataFrame(data)\n",
        "    st.dataframe(df, use_container_width=True)\n",
        "\n",
        "    # 다운로드\n",
        "    st.download_button(\"결과 CSV 다운로드\", data=df.to_csv(index=False).encode(\"utf-8\"), file_name=\"result.csv\")\n",
        "    if len(filtered_masks) > 0:\n",
        "        buf = io.BytesIO()\n",
        "        overlay.save(buf, format=\"PNG\")\n",
        "        st.download_button(\"결과 이미지 다운로드\", data=buf.getvalue(), file_name=\"seg_result.png\", mime=\"image/png\")\n",
        "\n",
        "    # ===================== Gemini 호출 준비 =====================\n",
        "    # seg_summary(파이프라인 JSON) 구성\n",
        "    bridge_id = os.path.splitext(uploaded.name)[0]\n",
        "    defects = []\n",
        "    for i, m in enumerate(filtered_masks):\n",
        "        geom = compute_geometry(m, gsd)\n",
        "        cname = class_names.get(filtered_labels[i], \"Unknown\")\n",
        "        defects.append({\n",
        "            \"class\": cname,\n",
        "            \"area_m2\": geom[\"area_m2\"],\n",
        "            \"length_m\": geom[\"length_m\"],\n",
        "            \"width_m\":  geom[\"width_m\"],\n",
        "            \"feret_m\":  geom[\"feret_m\"],\n",
        "            \"score\": float(filtered_scores[i]) if i < len(filtered_scores) else 0.0\n",
        "        })\n",
        "    seg_summary = {\n",
        "        \"bridge_id\": bridge_id,\n",
        "        \"bridge_type_input\": bridge_type,   # 사용자 입력\n",
        "        \"bridge_grade_input\": bridge_grade, # 사용자 입력\n",
        "        \"gsd_m_per_pixel\": gsd,\n",
        "        \"defects\": defects\n",
        "    }\n",
        "\n",
        "    # ===================== Gemini 버튼/출력 =====================\n",
        "    st.markdown(\"---\")\n",
        "    st.subheader(\"Gemini 2.5 Flash-Lite 판단\")\n",
        "    colA, colB = st.columns(2)\n",
        "    with colA:\n",
        "        do_expert = st.button(\"전문가 보고서(요약/세부/권고)\")\n",
        "    with colB:\n",
        "        do_light = st.button(\"짧은 결과(불릿 5줄 이내)\")\n",
        "\n",
        "    if do_expert or do_light:\n",
        "        try:\n",
        "            # 원본/오버레이 PIL → RGB 보장\n",
        "            img_rgb = img.convert(\"RGB\")\n",
        "            ovl_rgb = overlay if len(filtered_masks)>0 else img_rgb\n",
        "\n",
        "            mode = \"expert\" if do_expert else \"light\"\n",
        "            text = call_gemini_vlm(\n",
        "                img_rgb=img_rgb,\n",
        "                overlay_rgb=ovl_rgb,\n",
        "                seg_summary=seg_summary,\n",
        "                bridge_type=bridge_type,\n",
        "                bridge_grade=bridge_grade,\n",
        "                mode=mode\n",
        "            )\n",
        "            st.markdown(\"### Gemini 결과\")\n",
        "            st.write(text)\n",
        "        except Exception as e:\n",
        "            st.error(f\"Gemini 호출 실패: {e}\")\n",
        "\n",
        "PY"
      ],
      "metadata": {
        "id": "p6hTFh3e01hC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Line 19) best.pt 파일의 경로를 입력해주세요.\n",
        "# Line 155) Google API key의 경로를 입력해주세요."
      ],
      "metadata": {
        "id": "XgLlrybALmbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pyngrok 설치 (이미 설치했다면 생략)\n",
        "!pip install pyngrok -q\n",
        "\n",
        "# ngrok auth token 설정 (토큰을 안전하게 입력하세요)\n",
        "from pyngrok import ngrok\n",
        "NGROK_TOKEN = \"본인의 NGROK_TOKEN을 입력해주세요\"\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "# Streamlit 실행 (백그라운드)\n",
        "get_ipython().system_raw(\"streamlit run app.py &\")\n",
        "\n",
        "# ngrok으로 8501 포트 터널링\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(\"Public URL:\", public_url)\n"
      ],
      "metadata": {
        "id": "BRPbDcFUycKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Line 6) 사용자의 NGROK_TOKEN을 입력해주세요."
      ],
      "metadata": {
        "id": "bHiFVh1zL-Io"
      }
    }
  ]
}